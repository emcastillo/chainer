import unittest

import functools
import numpy
from operator import mul

import chainer
from chainer.backends import cuda
import chainer.functions as F
from chainer import testing
from chainer.testing import attr
from chainer.utils import conv


@testing.parameterize(*(testing.product({
    'dims': [(3, 4, 3)],
    'dilate': [1],
    'groups': [1],
    'cover_all': [False],
    'contiguous': ['C'],
    'x_dtype': [numpy.float32],
    'W_dtype': [numpy.float32],
    'b_dtype': [numpy.float32],
    'autotune': [False],
    'nobias': [True],
})
))
@testing.backend.inject_backend_tests(
    ['test_backward'],
    # GPU tests
    testing.product({
        'use_cuda': [True],
        'use_cudnn': ['always'],
    })
)
class TestConvolutionND(testing.FunctionTestCase):

    def setUp(self):
        self.N = 2
        self.in_channels = 4
        self.out_channels = 2
        self.ndim = len(self.dims)
        self.ksize = (2,) * self.ndim
        self.stride = (1,) * self.ndim
        self.pad = (1,) * self.ndim
        self.dilate = (self.dilate,) * self.ndim

        self.x_shape = (self.N, self.in_channels) + self.dims
        self.W_shape = (
            self.out_channels, self.in_channels // self.groups) + self.ksize
        self.W_scale = numpy.sqrt(
            1. / functools.reduce(mul, self.ksize, self.in_channels))
        self.gy_shape = (self.N, self.out_channels) + tuple(
            conv.get_conv_outsize(d, k, s, p, cover_all=self.cover_all, d=di)
            for (d, k, s, p, di)
            in zip(self.dims, self.ksize, self.stride, self.pad, self.dilate))

        self.check_backward_options.update({'atol': 5e-5, 'rtol': 5e-4})
        self.check_double_backward_options.update(
            {'atol': 5e-4, 'rtol': 5e-3})
        if self.x_dtype == numpy.float16 or self.W_dtype == numpy.float16:
            self.check_forward_options.update({'atol': 5e-4, 'rtol': 5e-3})
            self.check_backward_options.update({
                'atol': 2 ** -4, 'rtol': 2 ** -4})
            self.check_double_backward_options.update({
                'atol': 2 ** -4, 'rtol': 2 ** -4})

    def before_test(self, test_name):
        self.backend_config.autotune = self.autotune

    def generate_inputs(self):
        x = numpy.array([[[[[-0.8823272, 0.6131382,  0.86463654],
               [0.11194135, 0.88676322, 0.42647043],
               [-0.20192941, -0.98400348, -0.78130376],
               [-0.52930802, -0.19726318, 0.75485343]],
              [[0.04853087, -0.88076162, 0.86724848],
               [-0.31268078, -0.87448382, 0.10666238],
               [-0.98736793, -0.24605104, 0.02490044],
               [0.09785793, -0.1743833, -0.47036079]],
              [[-0.70007354, 0.82943285, 0.88016629],
               [0.10320293, 0.7133323, -0.7938081],
               [-0.286479, -0.67209786, 0.61273545],
               [-0.62313056, -0.84743476, -0.09276333]]],
             [[[-0.00610436, -0.1043255, -0.23532592],
               [0.23320048, -0.14558177, 0.76505369],
               [0.465639, 0.54129332, -0.26486519],
               [0.37524906, 0.12965487, -0.25241411]],
              [[0.56828195, 0.89734906, 0.46847522],
               [0.53712404, -0.66756177, 0.57094866],
               [0.23569751, -0.88983226, 0.72906196],
               [-0.54325289, 0.15825422, 0.74877274]],
              [[-0.13186575, -0.09333009, -0.06908098],
               [-0.2222739, -0.25785187, -0.08888257],
               [-0.02194866, 0.45750022, 0.42542419],
               [-0.72229141, -0.94305032, -0.72463328]]],
             [[[0.70540488, 0.56837678, -0.06946059],
               [0.12961771, -0.25402614, 0.07446931],
               [-0.79150587, -0.08218948, -0.51742911],
               [-0.85377777, -0.01509822, 0.80446208]],
              [[0.8697266, -0.35224861, 0.84715629],
               [0.68951064, -0.16286138, -0.69622082],
               [-0.78958714, -0.6864109, -0.76098889],
               [0.37617922, -0.56765538, -0.82319248]],
              [[-0.50741565, -0.18473019, 0.7298696],
               [0.87962466, -0.62938863, 0.97150195],
               [-0.93123907, 0.57831347, -0.08802591],
               [0.19540727, -0.58127904, 0.11935739]]],
             [[[0.85931116, 0.65560311, -0.50346762],
               [0.50876933, -0.66312152, 0.86391586],
               [0.96287495, 0.06403111, 0.60429794],
               [-0.74909413, 0.53354019, 0.90760392]],
              [[0.03315394, 0.14968276, -0.27573946],
               [0.99138457, -0.80701846, 0.36064494],
               [0.49557599, 0.82481426, 0.34359792],
               [0.38081279, 0.91443062, 0.09274513]],
              [[0.83713633, -0.47952798, 0.86369085],
               [-0.63290966, -0.2198915, 0.37171873],
               [-0.90874249, 0.0798021, 0.9095304],
               [-0.01114714, 0.52890921, 0.52052283]]]],
            [[[[0.15953584, -0.99280882, -0.24477039],
               [0.37755013, 0.6625936, -0.33255982],
               [-0.09177765, 0.55144459, 0.82491577],
               [0.55710524, -0.10613681, -0.11052907]],
              [[0.2743569, 0.26544088, 0.22575882],
               [0.88851726, -0.72325867, -0.02870545],
               [0.67766625, -0.29378873, -0.13693309],
               [-0.59440345, -0.24830411, -0.58396798]],
              [[0.36989325, -0.11707999, -0.99600804],
               [0.4859615, -0.58701789, -0.80845189],
               [0.70058149, -0.62604588, 0.97490805],
               [0.03108785, 0.62681627, 0.77645254]]],
             [[[-0.78873217, 0.46510237, 0.01201081],
               [0.60518181, 0.52379465, 0.73005897],
               [-0.54768783, -0.40876511, -0.42208949],
               [0.58165485, -0.59022409, -0.54840058]],
              [[0.99090958, -0.85471827, 0.79387909],
               [0.82515597, -0.36577663, 0.82126105],
               [0.19178699, -0.02151809, -0.51051307],
               [-0.41002381, 0.67360258, -0.19940946]],
              [[0.45562848, 0.08934583, 0.3303839],
               [0.67371607, -0.87731266, 0.78660667],
               [-0.01524884, 0.27006912, 0.54422331],
               [0.49809596, 0.79190499, 0.04763947]]],
             [[[0.7510668, 0.76562256, 0.73204446],
               [0.46194884, 0.60437506, 0.83596087],
               [-0.44507781, 0.26774451, -0.74094588],
               [-0.64627039, 0.91972882, -0.24656188]],
              [[0.2458199, 0.69617933, -0.29660469],
               [0.65255928, 0.11528312, -0.97463942],
               [0.02757186, 0.78420794, -0.80858713],
               [-0.75926483, 0.58702016, 0.84013724]],
              [[-0.76883537, -0.19646542, 0.04685465],
               [-0.56279647, -0.78189856, -0.45884079],
               [-0.07422841, -0.54840761, 0.59182304],
               [-0.20180023, 0.53715241, 0.0389958]]],
             [[[0.44247845, -0.7989729, 0.83005232],
               [-0.01062572, 0.21264425, 0.4322294],
               [-0.48983362, 0.11480696, 0.87325394],
               [-0.83909482, 0.89883769, -0.34270036]],
              [[-0.00654173, 0.28942293, -0.56598341],
               [-0.56195694, 0.00904089, -0.07872166],
               [-0.19466661, 0.46977082, 0.78525025],
               [-0.53416896, 0.55962253, 0.92392713]],
              [[0.42959198, 0.9770878, 0.73365742],
               [0.46095055, -0.37159741, 0.65967],
               [-0.33526066, -0.0426557, -0.89695048],
               [0.02912281, -0.65081209, 0.42873001]]]]], dtype=numpy.float32)
        w = numpy.array([[[[[-0.21628861, 0.13329744],
               [0.02105098, -0.06162651]],
              [[0.01125129, 0.18246424],
               [0.24662766, -0.20520839]]],
             [[[0.00401485, 0.04552686],
               [-0.27911061, 0.02265515]],
              [[0.25892466, 0.30617112],
               [-0.195509, 0.32488719]]],
             [[[-0.28197402, -0.14756326],
               [-0.21139102, -0.1064516]],
              [[-0.05848339, -0.35768339],
               [-0.10420159, -0.31264725]]],
             [[[-0.09139866, -0.12142801],
               [0.23019817, 0.04453282]],
              [[-0.17029288, 0.20243087],
               [0.05808243, 0.07410312]]]],
            [[[[0.04838814, -0.09385115],
               [-0.3233594, 0.16621442]],
              [[-0.25166276, 0.19395444],
               [0.09484466, 0.13010082]]],
             [[[0.03963762, 0.14212114],
               [-0.23330308, 0.07610424]],
              [[0.07381711, -0.15468371],
               [0.34201655, 0.02768536]]],
             [[[-0.18825535, -0.09148455],
               [-0.04662469, -0.14189774]],
              [[0.04120675, 0.20379175],
               [0.08808119, 0.13588923]]],
             [[[0.08068034, -0.20092404],
               [0.33406773, 0.25891271]],
              [[0.10604174, 0.07387235],
               [0.01128606, -0.08477429]]]]], dtype=numpy.float32)
        return x, w

    def forward_expected(self, inputs):
        if self.nobias:
            x, W = inputs
            b = None
        else:
            x, W, b = inputs
        y_expected = F.convolution_nd(
            x, W, b, stride=self.stride, pad=self.pad,
            cover_all=self.cover_all, dilate=self.dilate,
            groups=self.groups)
        return y_expected.array,

    def forward(self, inputs, device):
        if self.nobias:
            x, W = inputs
            b = None
        else:
            x, W, b = inputs
        y = F.convolution_nd(
            x, W, b, stride=self.stride, pad=self.pad,
            cover_all=self.cover_all, dilate=self.dilate,
            groups=self.groups)
        return y,


testing.run_module(__name__, __file__)
